{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vardansaini/Custom-T5/blob/main/CUSTOM_T5_Tensorflow(Not_working_so_far).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import time"
      ],
      "metadata": {
        "id": "FgvpTeQsyh1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow import keras\n",
        "# keras.__version__"
      ],
      "metadata": {
        "id": "nsXNkVwWd6yB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0S8jPhBKWLyo",
        "outputId": "ea5148ae-d1a2-4d5e-aa90-a69af09f3210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWd9TN6_cGRw"
      },
      "outputs": [],
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "\n",
        "  '''\n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable\n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  '''\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  if mask is not None:\n",
        "    mask = tf.cast(mask, tf.float32)\n",
        "    scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  print(\"att shape = \", attention_weights.shape)\n",
        "  print(\"v shape = \", v.shape)\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    print(d_model)\n",
        "    print(self.num_heads)\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def split_heads(self, x, batch_size):\n",
        "\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "\n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "      q, k, v, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                    (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "metadata": {
        "id": "KvjnbFVlcHsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \"\"\"\n",
        "#   MultiHeadAttention Usage:\n",
        "# \"\"\"\n",
        "# mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
        "# batch_size=1,\n",
        "# encoder_sequence=60\n",
        "# dimensions = 512\n",
        "# y = tf.random.uniform((batch_size, encoder_sequence, dimensions))\n",
        "# out, attn = mha(y, k=y, q=y, mask=None)\n",
        "# print(out.shape, attn.shape)"
      ],
      "metadata": {
        "id": "-BraTXtLcY74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])\n",
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    print(\"########################\")\n",
        "    print(\"Mask: \", mask)\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(out1, training=training)\n",
        "\n",
        "    ffn_output = self.ffn(attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    out2 = self.layernorm2(attn_output + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(out2, training=training)\n",
        "    return ffn_output"
      ],
      "metadata": {
        "id": "sba8EmZYcb42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # check this one again -- with the hugginface model\n",
        "# def point_wise_feed_forward_network(d_model, dff, rate=0.1):\n",
        "#   return tf.keras.Sequential([\n",
        "#       tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "#       tf.keras.layers.Dense(d_model),  # (batch_size, seq_len, d_model)\n",
        "#       tf.keras.layers.Dropout(rate)\n",
        "#   ])\n",
        "\n",
        "# class EncoderLayer(tf.keras.layers.Layer):\n",
        "#   def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "#     super(EncoderLayer, self).__init__()\n",
        "\n",
        "#     self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "#     self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "#     self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "#     self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "#     # self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "#     self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "#     self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "#     # self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "#   def call(self, x, training, mask):\n",
        "\n",
        "#     attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "#     attn_output = self.dropout1(attn_output, training=training)\n",
        "#     out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "#     ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "#     ffn_output = self.dropout2(ffn_output, training=training)\n",
        "#     out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "#     return out2"
      ],
      "metadata": {
        "id": "YL8d-bQMYmS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  # encoded_vec = np.array([pos/10000 ** (2*i/d_model) for pos in range(length) for i in range(d_model)],\n",
        "                          # dtype=tf.float32)\n",
        "  return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "  # print(\"###############################################################\")\n",
        "  # print([pos/10000 ** (2*i/d_model) for pos in range(position) for i in range(d_model)])\n",
        "  # angle_rads = tf.constant([pos/10000 ** (2*i/d_model) for pos in range(position) for i in range(d_model)], dtype=tf.float32)\n",
        "\n",
        "  # # apply sin to even indices in the array; 2i\n",
        "  # selected_elements = angle_rads[::2]\n",
        "  # sine_values = tf.sin(selected_elements)\n",
        "  # angle_rads = tf.tensor_scatter_nd_update(angle_rads, indices=tf.range(1, tf.size(angle_rads), 2)[:, tf.newaxis], updates=sine_values)\n",
        "\n",
        "  # angle_rads = np.sin(angle_rads[::2])\n",
        "  # angle_rads = angle_rads[::2]\n",
        "\n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  # angle_rads = np.cos(angle_rads[1::2])\n",
        "  # angle_rads = angle_rads[1::2]\n",
        "\n",
        "#   selected_elements = angle_rads[1::2]\n",
        "\n",
        "# # Compute the cosine of the selected elements\n",
        "#   cosine_values = tf.cos(selected_elements)\n",
        "\n",
        "# # Update the selected elements with their cosine values\n",
        "#   angle_rads = tf.tensor_scatter_nd_update(angle_rads, indices=tf.range(1, tf.size(angle_rads), 2)[:, tf.newaxis], updates=cosine_values)\n",
        "\n",
        "\n",
        "#     # return encoded_vec.reshape([sentence_length, dim])\n",
        "\n",
        "#   # pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "#   # return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "#    return encoded_vec.reshape([sentence_length, dim])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DcLW6LOJhjji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(input_vocab_size,\n",
        "                                            self.d_model)\n",
        "\n",
        "\n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
        "                       for _ in range(num_layers)]\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    print(\"seq_len: \",seq_len)\n",
        "\n",
        "    # adding embedding and position encoding.\n",
        "    print(\"I am in Encoder: \",x)\n",
        "    # x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    # might be an error since we got rid of embedding layer\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "    x = self.layernorm(x)  # (batch_size, input_seq_len, d_model)\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "\n",
        "    return x  # (batch_size, input_seq_len, d_model)"
      ],
      "metadata": {
        "id": "ht9SJTYJb3pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "    attn1 = self.dropout1(out1, training=training)\n",
        "\n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, attn1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    out2 = self.layernorm2(attn2 + attn1)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(out2, training=training)\n",
        "\n",
        "    ffn_output = self.ffn(attn2)  # (batch_size, target_seq_len, d_model)\n",
        "    out3 = self.layernorm3(ffn_output + attn2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.dropout3(out3, training=training)\n",
        "\n",
        "    return ffn_output, attn_weights_block1, attn_weights_block2"
      ],
      "metadata": {
        "id": "Aw3ZUVgcdIas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "\n",
        "    print(\"I am in decoder: \",x)\n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "\n",
        "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "\n",
        "    x = self.layernorm1(attention_weights + x)\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "\n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights"
      ],
      "metadata": {
        "id": "o-G4bL6Rdj8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    # self.shared = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
        "                           input_vocab_size, pe_input, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
        "                           target_vocab_size, pe_target, rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, inp, tar, training, enc_padding_mask,\n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "    # share = self.shared()\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "    return final_output, attention_weights"
      ],
      "metadata": {
        "id": "bQSPswhJdlHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow_datasets as tfds\n",
        "\n",
        "# def load_tokenizers(inputs_outputs_savepaths):\n",
        "#   print(\"Loading tokenizers...\")\n",
        "#   inputs_savepath, outputs_savepath = inputs_outputs_savepaths\n",
        "#   inputs_tokenizer = tfds.features.text.SubwordTextEncoder.load_from_file(inputs_savepath)\n",
        "#   outputs_tokenizer = tfds.features.text.SubwordTextEncoder.load_from_file(outputs_savepath)\n",
        "\n",
        "#   return inputs_tokenizer, outputs_tokenizer\n",
        "\n",
        "# def create_tokenizers(inputs_outputs, inputs_outputs_savepaths, target_vocab_size):\n",
        "#   inputs, outputs = inputs_outputs\n",
        "#   inputs_savepath, outputs_savepath = inputs_outputs_savepaths\n",
        "#   inputs_tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "#     inputs, target_vocab_size=target_vocab_size)\n",
        "#   outputs_tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "#     outputs, target_vocab_size=target_vocab_size)\n",
        "#   print(\"Saving tokenizers...\")\n",
        "#   inputs_tokenizer.save_to_file(inputs_savepath)\n",
        "#   outputs_tokenizer.save_to_file(outputs_savepath)"
      ],
      "metadata": {
        "id": "el85OGgQcEfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "id": "NAxa72XefUTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_path = \"/content/drive/MyDrive/\"\n",
        "with open(os.path.join(config_path,\"config.yml\")) as cf:\n",
        "  import yaml\n",
        "\n",
        "with open(os.path.join(config_path,\"config.yml\")) as cf:\n",
        "  config = yaml.load(cf, Loader=yaml.FullLoader)\n",
        "\n",
        "num_layers = config[\"num_layers\"]\n",
        "d_model = config[\"d_model\"]\n",
        "dff = config[\"dff\"]\n",
        "num_heads = config[\"num_heads\"]\n",
        "dropout_rate = config[\"dropout_rate\"]\n",
        "max_length = config[\"max_length\"]\n",
        "epochs = config[\"epochs\"]\n",
        "batch_size = config[\"batch_size\"]\n",
        "target_vocab_size = config[\"target_vocab_size\"]\n",
        "checkpoint = config[\"checkpoint\"]\n",
        "max_checkpoint = config[\"max_checkpoint\"]\n",
        "custom_checkpoint = config[\"custom_checkpoint\"]\n",
        "eval_limit = config[\"eval_limit\"]\n",
        "exit_phrase = config[\"exit_phrase\"]"
      ],
      "metadata": {
        "id": "6pXiNmpXfaBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup config file\n",
        "# num_layers: 4\n",
        "# target_vocab_size: 16000\n",
        "# d_model: 128\n",
        "# dff: 512\n",
        "# num_heads: 8\n",
        "# dropout_rate: 0.1\n",
        "# storage_path: null\n",
        "# max_length: 40\n",
        "# epochs: 100\n",
        "# batch_size: 64\n",
        "# ckpt_path : null\n",
        "# # save a checkpoint every x epochs\n",
        "# checkpoint: 5\n",
        "# max_checkpoint: 10\n",
        "# # select a custom checkpoint to start with\n",
        "# # (else it will automatically select the latest checkpoint)\n",
        "# custom_checkpoint: null\n",
        "# reddit_data: True\n",
        "\n",
        "# # train/eval/test/script\n",
        "# mode: \"test\"\n",
        "# eval_limit: 10\n",
        "# exit_phrase: \".exit\""
      ],
      "metadata": {
        "id": "bk1PNfDsfbZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_masks(src, tgt):\n",
        "  print(\"##############################\")\n",
        "  print(\"SRC: \", src)\n",
        "  print(\"#########\")\n",
        "  print(\"tgt: \", tgt)\n",
        "  print(\"##############################\")\n",
        "  src_mask = tf.math.not_equal(src, 0)[:, tf.newaxis, tf.newaxis]\n",
        "  tgt_mask = tf.math.not_equal(tgt, 0)[:, tf.newaxis, :, tf.newaxis]\n",
        "  seq_length = tf.shape(tgt)[1]\n",
        "  nopeak_mask = tf.linalg.band_part(tf.ones((1, seq_length, seq_length)), -1, 0)\n",
        "  nopeak_mask = tf.cast(nopeak_mask, dtype=tf.bool)\n",
        "  combined_mask = tgt_mask & nopeak_mask\n",
        "  return src_mask, combined_mask, tgt_mask"
      ],
      "metadata": {
        "id": "gOd4F0zMiyW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=(0.9, 0.98), epsilon=1e-9)\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "input_vocab_size = 1\n",
        "target_vocab_size = 1\n",
        "\n",
        "transformer = Transformer(\n",
        "                          num_layers, d_model,\n",
        "                          num_heads, dff,\n",
        "                          input_vocab_size,\n",
        "                          target_vocab_size,\n",
        "                          pe_input=input_vocab_size,\n",
        "                          pe_target=target_vocab_size,\n",
        "                          rate=dropout_rate)\n",
        "\n",
        "\n",
        "# train_step_signature = [\n",
        "#       tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "#       tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "#     ]\n",
        "print(\"I AM before train_step\")\n",
        "# @tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "    print(inp)\n",
        "    print(tar)\n",
        "    print(\"I am inside train step\")\n",
        "    tar_inp = tar[:, :-1]\n",
        "    print(tar_inp)\n",
        "    tar_real = tar[:, 1:]\n",
        "    print(tar_real)\n",
        "\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "    print(\"JUST GOT THROUGH CREATE MASKS\")\n",
        "    print(\"enc_padding_mask: \", enc_padding_mask)\n",
        "    print(\"combined_mask \", combined_mask)\n",
        "    print(\"dec_padding_mask\", dec_padding_mask)\n",
        "    print(\"starting predictions\")\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions, _ = transformer(inp, tar_inp,\n",
        "                                   True,\n",
        "                                   enc_padding_mask,\n",
        "                                   combined_mask,\n",
        "                                   dec_padding_mask\n",
        "                                   )\n",
        "      print(\"predictions\", predictions)\n",
        "      loss = loss_function(tar_real, predictions)\n",
        "      print(\"loss \", loss)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "    print(\"gradients \",gradients)\n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(tar_real, predictions)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      start = time.time()\n",
        "\n",
        "      train_loss.reset_states()\n",
        "      train_accuracy.reset_states()\n",
        "\n",
        "      batches_in, batches_out = train_dataset\n",
        "      for (batch, (inp, tar)) in enumerate(zip(batches_in, batches_out)):\n",
        "        train_step(inp, tar)\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "          print('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "              epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "\n",
        "      # if (epoch + 1) % checkpoint == 0:\n",
        "        # ckpt_save_path = ckpt_manager.save()\n",
        "        # print (f\"Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}\")\n",
        "\n",
        "      print(\"Epoch {} Loss {:.4f} Accuracy {:.4f}\".format(\n",
        "        epoch + 1, train_loss.result(), train_accuracy.result()))\n",
        "      print('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n"
      ],
      "metadata": {
        "id": "LQc3Lze3fhzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0dd60e6-5b0d-4380-d337-c5329d417642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "5\n",
            "50\n",
            "5\n",
            "50\n",
            "5\n",
            "50\n",
            "5\n",
            "50\n",
            "5\n",
            "50\n",
            "5\n",
            "50\n",
            "5\n",
            "50\n",
            "5\n",
            "50\n",
            "5\n",
            "50\n",
            "5\n",
            "50\n",
            "5\n",
            "50\n",
            "5\n",
            "I AM before train_step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# criterion = tf.keras.losses.CategoricalCrossentropy()\n",
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=(0.9, 0.98), epsilon=1e-9)\n",
        "\n",
        "# transformer.generate()\n",
        "\n",
        "# for epoch in range(100):\n",
        "#     optimizer.zero_grad()\n",
        "#     output = transformer(src_data, tgt_data[:, :-1])\n",
        "#     loss = criterion(output.contiguous().view(-1, tgt_vocab_size), tgt_data[:, 1:].contiguous().view(-1))\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "#     print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "id": "uOcPLgbeK9Hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove = ('/content/drive/MyDrive/glove.6B.50d.txt')"
      ],
      "metadata": {
        "id": "-hacRen7gLty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading glove text file\n",
        "with open(glove) as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "glove_dict = {}\n",
        "\n",
        "# converting in key value format\n",
        "# example (\"the\" : [\"0.22323\", \"0.0023232\", ......])\n",
        "for i in lines:\n",
        "  tokens  = i.split(\" \")\n",
        "  key = tokens[0]\n",
        "  tokens.pop(0)\n",
        "  value = tokens\n",
        "  glove_dict[key] = value\n",
        "\n",
        "print(len(glove_dict))"
      ],
      "metadata": {
        "id": "LhC6oUNhXCkh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08a99589-6c8d-424f-be5a-a04100fab987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading glove text file\n",
        "with open(glove) as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "glove_dict = {}\n",
        "\n",
        "# converting in key value format\n",
        "# example (\"the\" : [\"0.22323\", \"0.0023232\", ......])\n",
        "for i in lines:\n",
        "  tokens  = i.split(\" \")\n",
        "  key = tokens[0]\n",
        "  tokens.pop(0)\n",
        "  value = tokens\n",
        "  glove_dict[key] = value\n",
        "\n",
        "print(len(glove_dict))"
      ],
      "metadata": {
        "id": "8zNV3K8LXF6y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c6caf15-d1aa-415e-a2f3-f7058aefbd88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v = glove_dict['the']\n",
        "\n",
        "float_glove_dict = {}\n",
        "\n",
        "# converting values from string to float and muliplying to convert from floats to long/int later.\n",
        "for key, value in glove_dict.items():\n",
        "  l = []\n",
        "  for i in value:\n",
        "    # f = float(i) * 10000\n",
        "    f = float(i)\n",
        "    l.append(f)\n",
        "  float_glove_dict[key] = l"
      ],
      "metadata": {
        "id": "qmQgE272XPgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting to tensor\n",
        "\n",
        "count = 0\n",
        "tens = []\n",
        "for embeddings in float_glove_dict.values():\n",
        "  print(embeddings)\n",
        "  # j = torch.Tensor(embeddings)\n",
        "  # print(j[0])\n",
        "  # j = j.unsqueeze(0)\n",
        "  # tens.append(j)\n",
        "  int_embd = [float(i) for i in embeddings]\n",
        "  j = tf.constant(int_embd)\n",
        "  print(j[0].numpy())\n",
        "\n",
        "  j = tf.expand_dims(j, axis=0)\n",
        "  tens.append(j)\n",
        "  if count == 2:\n",
        "    break\n",
        "  count += 1\n",
        "\n",
        "# print(tens[0] * 10)\n",
        "\n",
        "\n",
        "\n",
        "print(tens)\n",
        "print(type(tens))\n",
        "print(len(tens))"
      ],
      "metadata": {
        "id": "L--kkhEyXJTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "491dd7e2-6fcf-4d34-d2fb-157ba836b508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.418, 0.24968, -0.41242, 0.1217, 0.34527, -0.044457, -0.49688, -0.17862, -0.00066023, -0.6566, 0.27843, -0.14767, -0.55677, 0.14658, -0.0095095, 0.011658, 0.10204, -0.12792, -0.8443, -0.12181, -0.016801, -0.33279, -0.1552, -0.23131, -0.19181, -1.8823, -0.76746, 0.099051, -0.42125, -0.19526, 4.0071, -0.18594, -0.52287, -0.31681, 0.00059213, 0.0074449, 0.17778, -0.15897, 0.012041, -0.054223, -0.29871, -0.15749, -0.34758, -0.045637, -0.44251, 0.18785, 0.0027849, -0.18411, -0.11514, -0.78581]\n",
            "0.418\n",
            "[0.013441, 0.23682, -0.16899, 0.40951, 0.63812, 0.47709, -0.42852, -0.55641, -0.364, -0.23938, 0.13001, -0.063734, -0.39575, -0.48162, 0.23291, 0.090201, -0.13324, 0.078639, -0.41634, -0.15428, 0.10068, 0.48891, 0.31226, -0.1252, -0.037512, -1.5179, 0.12612, -0.02442, -0.042961, -0.28351, 3.5416, -0.11956, -0.014533, -0.1499, 0.21864, -0.33412, -0.13872, 0.31806, 0.70358, 0.44858, -0.080262, 0.63003, 0.32111, -0.46765, 0.22786, 0.36034, -0.37818, -0.56657, 0.044691, 0.30392]\n",
            "0.013441\n",
            "[0.15164, 0.30177, -0.16763, 0.17684, 0.31719, 0.33973, -0.43478, -0.31086, -0.44999, -0.29486, 0.16608, 0.11963, -0.41328, -0.42353, 0.59868, 0.28825, -0.11547, -0.041848, -0.67989, -0.25063, 0.18472, 0.086876, 0.46582, 0.015035, 0.043474, -1.4671, -0.30384, -0.023441, 0.30589, -0.21785, 3.746, 0.0042284, -0.18436, -0.46209, 0.098329, -0.11907, 0.23919, 0.1161, 0.41705, 0.056763, -6.3681e-05, 0.068987, 0.087939, -0.10285, -0.13931, 0.22314, -0.080803, -0.35652, 0.016413, 0.10216]\n",
            "0.15164\n",
            "[<tf.Tensor: shape=(1, 50), dtype=float32, numpy=\n",
            "array([[ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n",
            "        -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n",
            "         2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n",
            "         1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n",
            "        -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n",
            "        -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n",
            "         4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n",
            "         7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
            "        -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n",
            "         1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(1, 50), dtype=float32, numpy=\n",
            "array([[ 0.013441,  0.23682 , -0.16899 ,  0.40951 ,  0.63812 ,  0.47709 ,\n",
            "        -0.42852 , -0.55641 , -0.364   , -0.23938 ,  0.13001 , -0.063734,\n",
            "        -0.39575 , -0.48162 ,  0.23291 ,  0.090201, -0.13324 ,  0.078639,\n",
            "        -0.41634 , -0.15428 ,  0.10068 ,  0.48891 ,  0.31226 , -0.1252  ,\n",
            "        -0.037512, -1.5179  ,  0.12612 , -0.02442 , -0.042961, -0.28351 ,\n",
            "         3.5416  , -0.11956 , -0.014533, -0.1499  ,  0.21864 , -0.33412 ,\n",
            "        -0.13872 ,  0.31806 ,  0.70358 ,  0.44858 , -0.080262,  0.63003 ,\n",
            "         0.32111 , -0.46765 ,  0.22786 ,  0.36034 , -0.37818 , -0.56657 ,\n",
            "         0.044691,  0.30392 ]], dtype=float32)>, <tf.Tensor: shape=(1, 50), dtype=float32, numpy=\n",
            "array([[ 1.5164e-01,  3.0177e-01, -1.6763e-01,  1.7684e-01,  3.1719e-01,\n",
            "         3.3973e-01, -4.3478e-01, -3.1086e-01, -4.4999e-01, -2.9486e-01,\n",
            "         1.6608e-01,  1.1963e-01, -4.1328e-01, -4.2353e-01,  5.9868e-01,\n",
            "         2.8825e-01, -1.1547e-01, -4.1848e-02, -6.7989e-01, -2.5063e-01,\n",
            "         1.8472e-01,  8.6876e-02,  4.6582e-01,  1.5035e-02,  4.3474e-02,\n",
            "        -1.4671e+00, -3.0384e-01, -2.3441e-02,  3.0589e-01, -2.1785e-01,\n",
            "         3.7460e+00,  4.2284e-03, -1.8436e-01, -4.6209e-01,  9.8329e-02,\n",
            "        -1.1907e-01,  2.3919e-01,  1.1610e-01,  4.1705e-01,  5.6763e-02,\n",
            "        -6.3681e-05,  6.8987e-02,  8.7939e-02, -1.0285e-01, -1.3931e-01,\n",
            "         2.2314e-01, -8.0803e-02, -3.5652e-01,  1.6413e-02,  1.0216e-01]],\n",
            "      dtype=float32)>]\n",
            "<class 'list'>\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input_ids = encoded_input.input_ids\n",
        "input_ids = tens[0]\n",
        "# print(torch.max(input_ids))\n",
        "# print(torch.max(input_ids, dim=0))\n",
        "# input_ids = input_ids.unsqueeze(0)\n",
        "print(input_ids.shape)\n",
        "# print(input_ids.unsqueeze(0))\n",
        "print(input_ids)\n",
        "print(type(input_ids))\n",
        "print(len(input_ids[0]))\n",
        "# attention_mask = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ],
      "metadata": {
        "id": "zVkU0HJVXjK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa2341e-4e01-47c9-94fb-7827b0a4745e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 50)\n",
            "tf.Tensor(\n",
            "[[ 4.1800e-01  2.4968e-01 -4.1242e-01  1.2170e-01  3.4527e-01 -4.4457e-02\n",
            "  -4.9688e-01 -1.7862e-01 -6.6023e-04 -6.5660e-01  2.7843e-01 -1.4767e-01\n",
            "  -5.5677e-01  1.4658e-01 -9.5095e-03  1.1658e-02  1.0204e-01 -1.2792e-01\n",
            "  -8.4430e-01 -1.2181e-01 -1.6801e-02 -3.3279e-01 -1.5520e-01 -2.3131e-01\n",
            "  -1.9181e-01 -1.8823e+00 -7.6746e-01  9.9051e-02 -4.2125e-01 -1.9526e-01\n",
            "   4.0071e+00 -1.8594e-01 -5.2287e-01 -3.1681e-01  5.9213e-04  7.4449e-03\n",
            "   1.7778e-01 -1.5897e-01  1.2041e-02 -5.4223e-02 -2.9871e-01 -1.5749e-01\n",
            "  -3.4758e-01 -4.5637e-02 -4.4251e-01  1.8785e-01  2.7849e-03 -1.8411e-01\n",
            "  -1.1514e-01 -7.8581e-01]], shape=(1, 50), dtype=float32)\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder_input_ids = decoded_input.input_ids\n",
        "\n",
        "decoder_input_ids = tens[1]\n",
        "print(decoder_input_ids.shape)\n",
        "print(decoder_input_ids)\n",
        "print(type(decoder_input_ids))\n",
        "print(len(decoder_input_ids[0]))\n",
        "# decoder_attention_mask = [1, 1, 1, 1, 1, 1, 1]"
      ],
      "metadata": {
        "id": "AgIa0A7oXp1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dea0733-a8e7-4634-ecb6-ac77a584fa92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 50)\n",
            "tf.Tensor(\n",
            "[[ 0.013441  0.23682  -0.16899   0.40951   0.63812   0.47709  -0.42852\n",
            "  -0.55641  -0.364    -0.23938   0.13001  -0.063734 -0.39575  -0.48162\n",
            "   0.23291   0.090201 -0.13324   0.078639 -0.41634  -0.15428   0.10068\n",
            "   0.48891   0.31226  -0.1252   -0.037512 -1.5179    0.12612  -0.02442\n",
            "  -0.042961 -0.28351   3.5416   -0.11956  -0.014533 -0.1499    0.21864\n",
            "  -0.33412  -0.13872   0.31806   0.70358   0.44858  -0.080262  0.63003\n",
            "   0.32111  -0.46765   0.22786   0.36034  -0.37818  -0.56657   0.044691\n",
            "   0.30392 ]], shape=(1, 50), dtype=float32)\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_step(input_ids, decoder_input_ids)"
      ],
      "metadata": {
        "id": "HVgG12Q8p2zl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d862d14b-0b33-4a2d-8512-59cf689ff755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 4.1800e-01  2.4968e-01 -4.1242e-01  1.2170e-01  3.4527e-01 -4.4457e-02\n",
            "  -4.9688e-01 -1.7862e-01 -6.6023e-04 -6.5660e-01  2.7843e-01 -1.4767e-01\n",
            "  -5.5677e-01  1.4658e-01 -9.5095e-03  1.1658e-02  1.0204e-01 -1.2792e-01\n",
            "  -8.4430e-01 -1.2181e-01 -1.6801e-02 -3.3279e-01 -1.5520e-01 -2.3131e-01\n",
            "  -1.9181e-01 -1.8823e+00 -7.6746e-01  9.9051e-02 -4.2125e-01 -1.9526e-01\n",
            "   4.0071e+00 -1.8594e-01 -5.2287e-01 -3.1681e-01  5.9213e-04  7.4449e-03\n",
            "   1.7778e-01 -1.5897e-01  1.2041e-02 -5.4223e-02 -2.9871e-01 -1.5749e-01\n",
            "  -3.4758e-01 -4.5637e-02 -4.4251e-01  1.8785e-01  2.7849e-03 -1.8411e-01\n",
            "  -1.1514e-01 -7.8581e-01]], shape=(1, 50), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.013441  0.23682  -0.16899   0.40951   0.63812   0.47709  -0.42852\n",
            "  -0.55641  -0.364    -0.23938   0.13001  -0.063734 -0.39575  -0.48162\n",
            "   0.23291   0.090201 -0.13324   0.078639 -0.41634  -0.15428   0.10068\n",
            "   0.48891   0.31226  -0.1252   -0.037512 -1.5179    0.12612  -0.02442\n",
            "  -0.042961 -0.28351   3.5416   -0.11956  -0.014533 -0.1499    0.21864\n",
            "  -0.33412  -0.13872   0.31806   0.70358   0.44858  -0.080262  0.63003\n",
            "   0.32111  -0.46765   0.22786   0.36034  -0.37818  -0.56657   0.044691\n",
            "   0.30392 ]], shape=(1, 50), dtype=float32)\n",
            "I am inside train step\n",
            "tf.Tensor(\n",
            "[[ 0.013441  0.23682  -0.16899   0.40951   0.63812   0.47709  -0.42852\n",
            "  -0.55641  -0.364    -0.23938   0.13001  -0.063734 -0.39575  -0.48162\n",
            "   0.23291   0.090201 -0.13324   0.078639 -0.41634  -0.15428   0.10068\n",
            "   0.48891   0.31226  -0.1252   -0.037512 -1.5179    0.12612  -0.02442\n",
            "  -0.042961 -0.28351   3.5416   -0.11956  -0.014533 -0.1499    0.21864\n",
            "  -0.33412  -0.13872   0.31806   0.70358   0.44858  -0.080262  0.63003\n",
            "   0.32111  -0.46765   0.22786   0.36034  -0.37818  -0.56657   0.044691]], shape=(1, 49), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.23682  -0.16899   0.40951   0.63812   0.47709  -0.42852  -0.55641\n",
            "  -0.364    -0.23938   0.13001  -0.063734 -0.39575  -0.48162   0.23291\n",
            "   0.090201 -0.13324   0.078639 -0.41634  -0.15428   0.10068   0.48891\n",
            "   0.31226  -0.1252   -0.037512 -1.5179    0.12612  -0.02442  -0.042961\n",
            "  -0.28351   3.5416   -0.11956  -0.014533 -0.1499    0.21864  -0.33412\n",
            "  -0.13872   0.31806   0.70358   0.44858  -0.080262  0.63003   0.32111\n",
            "  -0.46765   0.22786   0.36034  -0.37818  -0.56657   0.044691  0.30392 ]], shape=(1, 49), dtype=float32)\n",
            "##############################\n",
            "SRC:  tf.Tensor(\n",
            "[[ 4.1800e-01  2.4968e-01 -4.1242e-01  1.2170e-01  3.4527e-01 -4.4457e-02\n",
            "  -4.9688e-01 -1.7862e-01 -6.6023e-04 -6.5660e-01  2.7843e-01 -1.4767e-01\n",
            "  -5.5677e-01  1.4658e-01 -9.5095e-03  1.1658e-02  1.0204e-01 -1.2792e-01\n",
            "  -8.4430e-01 -1.2181e-01 -1.6801e-02 -3.3279e-01 -1.5520e-01 -2.3131e-01\n",
            "  -1.9181e-01 -1.8823e+00 -7.6746e-01  9.9051e-02 -4.2125e-01 -1.9526e-01\n",
            "   4.0071e+00 -1.8594e-01 -5.2287e-01 -3.1681e-01  5.9213e-04  7.4449e-03\n",
            "   1.7778e-01 -1.5897e-01  1.2041e-02 -5.4223e-02 -2.9871e-01 -1.5749e-01\n",
            "  -3.4758e-01 -4.5637e-02 -4.4251e-01  1.8785e-01  2.7849e-03 -1.8411e-01\n",
            "  -1.1514e-01 -7.8581e-01]], shape=(1, 50), dtype=float32)\n",
            "#########\n",
            "tgt:  tf.Tensor(\n",
            "[[ 0.013441  0.23682  -0.16899   0.40951   0.63812   0.47709  -0.42852\n",
            "  -0.55641  -0.364    -0.23938   0.13001  -0.063734 -0.39575  -0.48162\n",
            "   0.23291   0.090201 -0.13324   0.078639 -0.41634  -0.15428   0.10068\n",
            "   0.48891   0.31226  -0.1252   -0.037512 -1.5179    0.12612  -0.02442\n",
            "  -0.042961 -0.28351   3.5416   -0.11956  -0.014533 -0.1499    0.21864\n",
            "  -0.33412  -0.13872   0.31806   0.70358   0.44858  -0.080262  0.63003\n",
            "   0.32111  -0.46765   0.22786   0.36034  -0.37818  -0.56657   0.044691]], shape=(1, 49), dtype=float32)\n",
            "##############################\n",
            "JUST GOT THROUGH CREATE MASKS\n",
            "enc_padding_mask:  tf.Tensor(\n",
            "[[[[ True  True  True  True  True  True  True  True  True  True  True\n",
            "     True  True  True  True  True  True  True  True  True  True  True\n",
            "     True  True  True  True  True  True  True  True  True  True  True\n",
            "     True  True  True  True  True  True  True  True  True  True  True\n",
            "     True  True  True  True  True  True]]]], shape=(1, 1, 1, 50), dtype=bool)\n",
            "combined_mask  tf.Tensor(\n",
            "[[[[ True False False ... False False False]\n",
            "   [ True  True False ... False False False]\n",
            "   [ True  True  True ... False False False]\n",
            "   ...\n",
            "   [ True  True  True ...  True False False]\n",
            "   [ True  True  True ...  True  True False]\n",
            "   [ True  True  True ...  True  True  True]]]], shape=(1, 1, 49, 49), dtype=bool)\n",
            "dec_padding_mask tf.Tensor(\n",
            "[[[[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]]], shape=(1, 1, 49, 1), dtype=bool)\n",
            "starting predictions\n",
            "seq_len:  tf.Tensor(50, shape=(), dtype=int32)\n",
            "I am in Encoder:  tf.Tensor(\n",
            "[[ 4.1800e-01  2.4968e-01 -4.1242e-01  1.2170e-01  3.4527e-01 -4.4457e-02\n",
            "  -4.9688e-01 -1.7862e-01 -6.6023e-04 -6.5660e-01  2.7843e-01 -1.4767e-01\n",
            "  -5.5677e-01  1.4658e-01 -9.5095e-03  1.1658e-02  1.0204e-01 -1.2792e-01\n",
            "  -8.4430e-01 -1.2181e-01 -1.6801e-02 -3.3279e-01 -1.5520e-01 -2.3131e-01\n",
            "  -1.9181e-01 -1.8823e+00 -7.6746e-01  9.9051e-02 -4.2125e-01 -1.9526e-01\n",
            "   4.0071e+00 -1.8594e-01 -5.2287e-01 -3.1681e-01  5.9213e-04  7.4449e-03\n",
            "   1.7778e-01 -1.5897e-01  1.2041e-02 -5.4223e-02 -2.9871e-01 -1.5749e-01\n",
            "  -3.4758e-01 -4.5637e-02 -4.4251e-01  1.8785e-01  2.7849e-03 -1.8411e-01\n",
            "  -1.1514e-01 -7.8581e-01]], shape=(1, 50), dtype=float32)\n",
            "########################\n",
            "Mask:  tf.Tensor(\n",
            "[[[[ True  True  True  True  True  True  True  True  True  True  True\n",
            "     True  True  True  True  True  True  True  True  True  True  True\n",
            "     True  True  True  True  True  True  True  True  True  True  True\n",
            "     True  True  True  True  True  True  True  True  True  True  True\n",
            "     True  True  True  True  True  True]]]], shape=(1, 1, 1, 50), dtype=bool)\n",
            "att shape =  (1, 5, 1, 50)\n",
            "v shape =  (1, 5, 1, 10)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-147-ca3e6dbc6c04>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-142-9c94c48c8259>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(inp, tar)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"starting predictions\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m       predictions, _ = transformer(inp, tar_inp,\n\u001b[0m\u001b[1;32m     43\u001b[0m                                    \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                                    \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-125-f0030b7f2730>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# share = self.shared()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0menc_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, inp_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# dec_output.shape == (batch_size, tar_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-122-0f2e8b8037cf>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, training, mask)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, input_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-119-8fabfa41e4f7>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, training, mask)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"########################\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mask: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, input_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, input_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-117-0749f9f0f110>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, v, k, q, mask)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, num_heads, seq_len_v, depth)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     scaled_attention, attention_weights = scaled_dot_product_attention(\n\u001b[0m\u001b[1;32m     36\u001b[0m       q, k, v, mask)\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-141-4a97468aa4e1>\u001b[0m in \u001b[0;36mscaled_dot_product_attention\u001b[0;34m(q, k, v, mask)\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"att shape = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"v shape = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (..., seq_len_q, depth_v)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'multi_head_attention_60' (type MultiHeadAttention).\n\n{{function_node __wrapped__BatchMatMulV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [1,5,1,50], In[1]: [1,5,1,10] [Op:BatchMatMulV2] name: \n\nCall arguments received by layer 'multi_head_attention_60' (type MultiHeadAttention):\n   v=tf.Tensor(shape=(1, 1, 50), dtype=float32)\n   k=tf.Tensor(shape=(1, 1, 50), dtype=float32)\n   q=tf.Tensor(shape=(1, 1, 50), dtype=float32)\n   mask=tf.Tensor(shape=(1, 1, 1, 50), dtype=bool)"
          ]
        }
      ]
    }
  ]
}